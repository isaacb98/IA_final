# Information Arhcitecture Final Overview

### Step 1 - Define the problem

Our group identified a need to gather data on the health ratings of restaurants in Manhattan and their corresponding Yelp reviews in order to determine if the health rating provided by the government was correlated to the customers enjoying more or less the restaurant. 

### Step 2 - Choose tools and technologies

Our group decided to use Python as the primary programming language for the project. Additionally, we used AWS Lambda to automate the scraping process, AWS S3 bucket to store the data, AWS Glue to store the data in MySQL, and Tableau for data visualization.

### Step 3 - Collect data 

Our group wrote Python scripts to scrape the NYC Open Data website and Yelp for restaurant data. We used AWS Lambda to automate this process, which saved time and improved efficiency.

### Step 4 - Store data

Once the data was scraped, we stored it in an AWS S3 bucket. From there, we used AWS Glue to extract, transform, and load the data into MySQL.

### Step 5 - Connect to Tableau

Our group connected our environment to Tableau. This allowed you to create visualizations of the data stored in MySQL.

### Step 6 - Create visualizations

With Tableau, we were able to create visualizations that helped us identify trends and patterns in the data. These visualizations were useful for understanding the health ratings of restaurants in Manhattan and their corresponding Yelp reviews.

### Conclusion

Overall, our group's project was a combination of Python, AWS services, and Tableau. By automating the data collection process, storing it in a database, and visualizing it in a meaningful way, we were able to provide valuable insights into the health ratings of restaurants in Manhattan. This project demonstrates the power of technology and data analysis in solving real-world problems.
![image](https://github.com/isaacb98/IA_final/assets/112417920/3f19f202-3f2a-4c61-bbcf-37b1ae4263c0)
